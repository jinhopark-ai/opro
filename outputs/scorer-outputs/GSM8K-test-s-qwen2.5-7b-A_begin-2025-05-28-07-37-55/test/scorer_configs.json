{
    "model_type": "qwen2.5-7b",
    "temperature": 0.0,
    "num_servers": 1,
    "batch_size": 2048,
    "max_decode_steps": 1024
}